+++
date = "2018-04-09T07:00:00"
title = "我去美國讀博這五年"
titleimage = "https://pic1.zhimg.com/v2-67088b10dbe889fdfa64f7fd06b90b84.jpg"
ga = 040907
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">



<div class="question">
<h2 class="question-title">博士這五年</h2>
<div class="answer">



<div class="content">
<p><strong>前言</strong></p>
<p>12 年 8 月提着一個行李箱降落在匹茲堡機場。沒找住的地方，也不知道 CMU 應該怎麼去。對未來一片迷茫，但充滿樂觀。 現在，剛完成了博士期間最後的一場報告，在同樣的機場，不過是在等待離開的航班。</p>
<p>回想過去的五年，是折騰的五年，也是自我感悟和提升的五年。這裏我嘗試記錄這五年主要做過的事情和其中的感想，希望對大家有所啓發。</p>
<p><strong>第 0 年：3/11-8/12</strong></p>
<p>我第一次申請美國的博士是在 11 年，但拿到的 offer 並沒有特別合適的導師，於是就北上投奔文淵去了。 我當時在百度商務搜索部門做廣告的點擊預估。具體是使用機器學習來預測一個廣告是不是會被用戶點擊。 這時候離“大數據”這個詞流行還有兩年，但百度那時候的數據即使現在來看仍然是大的。我的任務是如何高效的利用數百臺機器快速的在數十 T 的數據上訓練出模型。</p>
<p>當時產品用的算法基於 LBFGS，我於是想是不是可以換個收斂更快的算法。沒幾天就找到個不錯 。但實現上發現了各種問題，包括性能，收斂，和穩定性。而且那時有的就是一個裸的 Linux 和很老版本的 GCC，什麼都是需要從頭開始寫。花了大量時間做系統優化，算法改動，和線上實驗，最後一年後在整個廣告流量上上了線。</p>
<p>現在再回顧會覺得整個一年時間都在打磨各種細節上，有時候爲了 5%的性能提升花上上千行代碼。這些都導致算法過於複雜，有過度設計之嫌。但深入各個細節對個人能力提升很大，而且很多遇到的問題成爲了之後研究方向的來源。一些算法上的思考曾寫在<a class=" wrap external" href="http://link.zhihu.com/?target=http%3A//mli.github.io/2013/03/24/the-end-of-feature-engineering-and-linear-model/" target="_blank" rel="nofollow noreferrer">這裏</a>，當時候深度學習剛剛出來，冥冥中覺得這個應該是大規模機器學習的未來，不過真正開始跟進是好幾年以後了。</p>
<p>11 年 12 月中的時候突然心血來潮隨手把材料重新寄了一遍，就選了 CMU 和 MIT，結果意外收到了 CMU 的 offer。有天在百度食堂同凱哥（餘凱）和潼哥（張潼）吃飯，我說收了 CMU offer，在糾結去不去。他們立馬說去跟 Alex Smola 啊，他要要加入 CMU 了，我們給你引薦下。</p>
<p>記得是離開的前一天才開始打包行李，早上去公司開完會，中午離職，跟小夥伴打招呼說出個國，然後就奔機場了。那天北京天氣特別好，完全不記得前一天霧霾剛爆了表。</p>
<p><strong>第一年：9/12-8/13</strong></p>
<p>第一年的主要事情是熟悉環境和上課。CMU 課程比較重，博士需要學 8 門課，每門課工作量巨大。而且要求做兩門課助教，做助教比上課更累。</p>
<p>這一年上的課中對我最有用的是“高級分佈式系統”。之前在上交 ACM 班的時候已經學過很多質量都還不錯課，純知識性的課程一般對我幫助不大。但這門課主要是讀論文，然後大家討論。不僅僅是關於知識，很多是對設計理念的領悟。大家知道對於系統而言，設計是一門藝術而不是科學，這是設計者審美和哲學理念的體現。同時系統界歷史也是由一波又一波的潮流組成，瞭解歷史的發展以及其中不斷重複的規律非常有意義。</p>
<p>那年這門課上課老師是 Hui Zhang（神人之一，20 多歲就在 CMU 任教了，學生包括了 Ion Stoica，他是 Spark 作者 Matei 的導師），他有非常好的大局觀，對於“Why”這個問題闡述非常到位。我是通過這門課纔對分佈式系統有了比較清晰的認識。兩年之後我偶然發現我的一篇論文也在這門課的閱讀列表裏了，算是小成就達成 。</p>
<p>除了上課，更重要是做研究。我去 CMU 的時候 Alex 那時還在 Google，而且沒經費，所以把我丟給了 Dave Andersen。於是我有了兩個導師，一個做機器學習，一個做分佈式系統。</p>
<p>前面半年都是在相互熟悉的過程。我們每週會一起聊一個小時。前半年因爲 Alex 不在，所以我們只能視頻。Alex 那邊信號經常不好，而且他有德國和澳大利亞口音，外加思維跳躍，經常我聽不懂他說啥只能賣萌傻笑。還是靠着 Dave 不斷的打字告訴我 Alex 說了什麼才度過了前幾次的會。</p>
<p>兩個導師風格迥異。Alex 是屬於反應特別快，通常你說一點，他已經想好了接下來十點，要跟上他節奏很難。一般拋出問題的時候他就想好了好幾個解決方法。這時候要證明自己的想法比他的更好不容易，需要大量的溝通和實驗數據支撐。我想我大概是花了兩年證明了在某些方向上我的方案一般更好，所以這時候他就不那麼 hands-on 了。</p>
<p>Dave 不會給很多想法，但會幫助把一個東西理解透，然後講得很清楚。因爲我研究方向主要是機器學習上，基本上前兩年基本都是我在教 Dave 什麼叫機器學習，而且是儘量不用公式那種教法。</p>
<p>我的第一個研究工作是關於如果劃分數據和計算使得減少機器學習求解中的網絡通訊量。Alex 體現了他的強項，幾分鐘就把問題歸納成了一個優化問題，然後我們三各自提出一個解法。我做了做實驗發現 Dave 的算法更好。接下來兩個月把算法做了很多優化，然後又做了點理論分析就把論文寫了。</p>
<p>可惜這個想法似乎有點超前，雖然我們一遍又一遍的改進寫作，但投了好幾個會審稿人就是不理解，或者覺得這個問題不重要。那個時候學術界已經開始吹噓“大數據”，但我覺得其實大部分人是不懂的，或者他們的“大數據”仍然是幾個 GB 的規模，烤 U 盤需要十來分鐘的那種。</p>
<p>這是我在 CMU 的一個工作，我覺得挺有用，但卻是唯一沒能發表的。</p>
<p>當時跟我坐同一個辦公室的是 Richard Peng，他做的是理論研究。我經常跟他討論問題，然後有了些想法合作了一個工作。大體思想是把圖壓縮的快速算法做到矩陣的低秩近似上。這個工作寫了三十頁公式但沒有任何實驗，我主要當做寫代碼間隙的悠閒娛樂，不過運氣很好的中了 FOCS。</p>
<p>坦白說我不是特別喜歡純理論這種，例如在 bound 的證明中很多大量的項直接丟掉了，導致我覺得 bound 特別的近似。對於做系統的人來說，最後拼的是常數。這個工作中這種大開大合的做法我覺得很不踏實。所以我覺得以後還是應該做更實在點的東西。</p>
<p>在 CMU 回到了去百度前的一週七天工作無休的節奏。每週至少 80 個小時花在學校。如果累了就去健身房，我一般晚上 12 點去。不僅是我一個人，大家都很努力，例如凌晨的健身房，早 3 點的辦公室，四處都可以見到中國或者印度學生。我那時候的室友田淵棟花在學校的時候比我多很多。</p>
<p>那一陣子有讀了很多關於優化的文章。其中對我啓發最大的是 Bertsekas 寫於 80 年代末的那本關於分佈式計算的書。此書可以認爲是 MIT 控制領域黃金一代研究成果總結，換到現在仍然不過時。</p>
<p>受啓發我轉去研究異步算法，就是分佈式下不保證數據的及時性來提升系統性能。我基於在百度期間做的算法，做了一些改進和理論分析，然後投了 NIPS。</p>
<p>投完 NIPS 就動身去了 Google Research 實習。那時候 Google Brain 成立不久，在“宇宙的答案”42 樓，包括 Jeff Dean，Geoffrey Hinton，Prabhakar Raghavan 好些大牛擠在一起，加起來論文引用率能超 80 萬。</p>
<p>Alex 跟我說，你去讀讀 Jure Leskovec 的文章，學學人家怎麼講故事。我在 Google 也嘗試用了些用戶 GPS 數據來對用戶行爲建模。可是寫文章的時候怎麼也寫不出 Jure 的那種故事感，發現自己不是那塊料。這篇文章因爲用了用戶數據，恰逢 Snowden 讓大家意識到隱私的重要性，歷經艱辛刪了一半結果 Google 才允許發出來。有些累覺不愛。</p>
<p>不過在 Google 期間我主要時間花在研究內部代碼和文檔上。Google 的基礎架構很好，文檔也很健全。雖然沒有直接學到了什麼，但至少是開了眼界。</p>
<p><strong>第二年：9/13-8/14</strong></p>
<p>這學期上了 Tuomas Sandholm 的機制設計，此乃另一大神，例如最近德州撲克贏了專業選手，之前開公司也賣了上億。不過這門課我是完完全全沒學懂，連承諾的課程大作業都沒怎麼做出來。之後的兩年裏我一遇到 Tuomas 他都會問下有什麼進展沒。我只能遠遠看見他就繞開。</p>
<p>NIPS 被拒了，發現審稿人不懂線程和進程的區別，有點沮喪。隔壁實驗室一篇想法類似但簡單很多的論文倒是中了 oral，所以那陣子壓力很大。Alex 安慰說這種事情常有發生，看淡點，然後舉了很多自己的例子。</p>
<p>之後想了想，一篇好文章自然需要有足夠多的“乾貨”，或者說信息量， 但一篇能被接受的文章需要滿足下面這個公式：</p>
<blockquote>文章的信息量 / 文章的易讀性 &lt; 審稿人水平 * 審稿人花的時間</blockquote>
<p>對於機器學習會議，因爲投稿量大，所以審稿人很多自然平均水平就會下降。而且很多審稿人就花半個小時到一個小時來讀文章，所以公式右邊數值通常是很小，而且不是我們能控制。</p>
<p>如果文章的信息量不大，例如是改進前面工作或者一些簡單的新想法，那麼公式成立的概率很大。而對於信息量大的文章，就需要努力提升易讀性，包括清晰的問題設定，足夠的上下文解釋等等。而前面投的那篇 NIPS，以及更早的那個被拒工作，就是因爲我們假設了審稿人有足夠多的相關專業知識，而我們塞進了太多幹貨使得大家都讀糊塗了。</p>
<p>即使對於已經發表的文章，上面那個公式同樣可以用來衡量一篇論文的引用率。例如經常見到乾貨很多的文章沒有什麼人引用，而同時期的某些工作就是考慮了其中簡單特殊情況結果被大引特引。</p>
<p>接下來的半年我主要在做一個通用的分佈式機器學習框架，是想以後做實驗方便些。名字就叫 parameter server，沿用了 Alex 10 年論文提出的名字。花了很多時間在接口設計上，做了好幾個版本實現，也跑了些工業界級別的大規模的實驗。</p>
<p>不過真正花了我大量時間的是在寫論文上。目標是把這個工作投到 OSDI 上，OSDI 是系統界兩大會之一。我們預計審稿人跟 Dave 兩年前狀態差不多，不會有太多機器學習和數學背景，所以需要儘量的少用公式。整整一個月就花在寫論文上，14 頁的文章滿滿都是文字和示意圖。不過努力沒有白費，最終論文被接受了。隨後又花了好幾周準備大會報告上。相對於平時花一週寫論文，兩三天準備報告，這次在寫作和報告水平上有了很大的提升。沒有放進去的公式和定理投了接下來的 NIPS，這次運氣很好的中了。</p>
<p>有了文章後稍微心安了點可以更自由的做些事情。</p>
<p>寒假回了趟國，跑去百度找了凱哥和潼哥。潼哥說他最近有個想法，於是快糙猛的把實驗做了然後寫了篇論文投了 KDD。同時期 Alex 一個學生也把他一個一直想讓我做但我覺得這個小 trick 不值得我花時間的想法投了 KDD，結果中了最佳論文。作報告那天我在的會場稀稀疏疏幾個人，他們隔壁會場人山人海。這個使得好長一段時間我都在琢磨是不是還是要跟着導師走比較好。</p>
<p>那時凱哥在百度搞少帥計劃，覺得蠻合適就加入了。這時凱哥正帶着一大幫兄弟轟轟烈烈的搞深度學習，我自然也是跳坑了。試過好幾個想法後，我覺得做做分佈式的深度學習框架比較對胃口。我挑了 CXXNet 作爲起點，主要是因爲跟天奇比較熟。同時也慢慢上手跑一些 Alexnet 之類的實驗。</p>
<p>我是因爲少帥計劃纔開始開始做深度學習相關項目，凱哥也很支持我做開源開發回饋社會而不是隻做公司內部的產品。但在少帥期間並沒有做出什麼對公司有幫助的事，很是慚愧。</p>
<p><strong>第三年：9/14-8/15</strong></p>
<p>回 CMU 後 Alex 看見深度學習這麼火，說我們也去買點 GPU 玩玩。但我們比較窮，只能去 newegg 上掏點便宜貨。這個開啓了轟轟烈烈的機器折騰之旅。整個一年我覺得我都在買買買裝裝裝上。最終我們可能就花了小几萬刀攢出了一個有 80 塊 GPU 的集羣。現在想想時間上花費不值得，而且爲了圖便宜買了各種型號的硬件導致維護成本高。但當時候樂在其中。具體細節可以看這篇 <a class=" wrap external" href="http://link.zhihu.com/?target=http%3A//mli.github.io/gpu/2016/01/17/build-gpu-clusters/" target="_blank" rel="nofollow noreferrer">blog</a></p>
<p>這一年寫了很多 parameter server 代碼，同時花了很時間幫助用戶使用這些代碼。很難說做得很成功，現在想想有幾個原因。寫代碼時我會優先考慮性能和支持最多的機器學習算法。但正如前面的錯誤，忽略了代碼的易讀性，從而導致只有少部分人能理解代碼從而做一些開發。例如我嘗試讓 Alex 組的學生來使用這些代碼，但其中的各種異步和 callback 讓他們覺得很是難懂。其次是沒有人能一起審覈代碼接口，導致這些接口有濃濃的個人味道，很難做到對所有人都簡單明瞭。</p>
<p>不過幸運的是找到一幫志同道合的小夥伴。最早是我發現天奇在寫 xgboost 的分佈式啓動腳本，我看了看發現挺好用，就跟他聊了聊。聊下的發現有很多基礎部件例如啓動腳本，文件讀取應該是可以多個項目共同使用，而不是每個項目都造一個輪子。於是跟天奇在 Github 上創建了一個叫 DMLC 的組織，用來加強合作和溝通。第一個項目是 dmlc-core，放置了啓動和數據讀取代碼。</p>
<p>DMLC 的第二個新項目叫 wormhole。想法是提供一系列分佈式機器學習算法，他們使用差不多相同的配置參數來統一用戶體驗。我把 parameter server 裏面的機器學習相關算法移植了過來，天奇移植了 xgboost。Parameter server 原有的系統代碼簡化到了 ps-lite。</p>
<p>中途我聽百度同學說 factorization machine（FM）在廣告數據上效果不錯，所以在 wormhole 上實現了下。針對分佈式做了一些優化，然後投了 WSDM。前後沒有花到一個月，但神奇的竟然拿了最佳論文提名。</p>
<p>在 wormhole 的開發中發現一個問題，就是各個算法還是挺不一樣，他們可以共用一些代碼，但又有各自的特點，需要特別的優化來保證性能。這樣導致維護有些困難，例如對共用代碼的改動導致所有項目都要檢查下。總結下來覺得一個項目最好只做一件事情。所以天奇把 xgboost 代碼放回原來項目，我也把 FM 獨立出來一個項目叫 difacto。</p>
<p>通過一系列的項目，我學到的一點是，以目前的水平和人力，做一個通用而且高效的分佈式機器學習框架是很難的一件事情。比較可行的是針對一類相似的機器學習算法做針對性的項目。這個項目的接口必須是符合這類算法結構，所以做算法開發的同學也能容易理解，而不是過多暴露底層系統細節。</p>
<p>真正的讓 DMLC 社區壯大的項目是第三個，叫做 MXNet。當時的背景是 CXXNet 達到了一定的成熟度，但它的靈活性有侷限性。用戶只能通過一個配置項來定義模型，而不是交互式的編程。另外一個項目是 zz 和敏捷他們做的 Minerva，是一個類似 numpy 的交互式編程接口，但這個靈活的接口對穩定性和性能優化帶來很多挑戰。我當時候同時給兩個項目做分佈式的擴展，所有都有一定的瞭解。然後一個自然的想法是，把兩個項目合併起來取長補短豈不是很好。</p>
<p>召集了兩個項目的開發人員討論了幾次，有了大致的眉目。新項目取名 MXNet，可以叫做 mixed-net，是前面兩個名字（Minerva 和 CXXNet）的組合。放棄開發了幾年的項目不是容易的決定，但幸運的是小夥伴都願意最求更好，所以 MXNet 進展挺順利。很快就有了可以跑的第一個版本。</p>
<p><strong>第四年：9/15-8/16</strong></p>
<p>前半年爲 difacto 和 MXNet 寫了很多代碼。其實一開始的時候我覺得 difacto 更重要些，畢竟它對於線性算法的提升非常顯著而且額外的計算開銷並不大，這對廣告預估之類的應用會有非常大的提升。但有次遇到 Andrew Ng，我跟他說我同時在做這兩個項目，他立即告訴我我應該全部精力放在 MXNet 上，這個的未來空間會大很多。我一直很佩服 Andrew 的眼光，所以聽了他的建議。</p>
<p>11 月的時候 MXNet 就有了很高的完成度。寫了個小論文投去了 NIPS 的 workshop 也算是歇了口氣。但隨後就聽到了 TensorFlow（TF）開源的消息。由 Jeff Dean 領導大量全職工程師開發，Google 龐大的宣傳機器支持，不出意料迅速成爲最流行的深度學習平臺。TF 對我們壓力還是蠻大，我們有核心開發者轉去用了 TF。不過 TF 的存在讓我領悟到一點，與其過分關心和擔憂對手，不如把精力集中在把自己的做得更好。</p>
<p>NIPS 的時候 MXNet 的小夥伴聚了一次，有好幾個我其實是第一次見面。隨後 Nvidia 的 GTC 邀請我們去做報告。在這兩次之間大家爆發了一把，做了很多地方的改進。同時用戶也在穩步增長。我們一直覺得 MXNet 是小開發團隊所以做新東西快這是一個優勢，但隨着用戶增加，收到抱怨說開發太快導致很多模塊兼容性有問題。有段時間也在反思要在新技術開發速度和穩定性之間做一些權衡。</p>
<p>這時一夜之間大數據不再流行，大家都在談深度學習了。</p>
<p>我也花了很多力氣在宣傳 MXNet 和爭取開發者上。包括微博知乎上吼一吼，四處給報告。在大量的點贊聲中有些陶醉，但很多中肯的批評也讓我意識到重要的一點，就是應該真誠的分享而不是簡單的吹噓。</p>
<p>因爲大量的媒體介入，整個深度學習有娛樂化的趨勢。娛樂化的報道很多都只是一些簡單信息，（有偏見）的觀點，而沒有太多幹貨。不僅對別人沒營養，對自己來說也就是滿足虛榮心。與其寫這些簡單的水文，不如靜下心做一些有深度的分享，包括技術細節，設計思路，和其中的體會。</p>
<p>此類分享一個容易陷入的誤區是隻關注自己做了什麼，結果多麼好。這些確實能證明個人能力，對於想重複這個工作的人來說會有很大幫助。但更多的人更關心的是適用範圍在哪裏，就是什麼情況下效果會減弱；爲什麼結果會那麼好；insight 是什麼。這個需要更多深入的理解和思考，而不是簡單的展示結果。</p>
<p>這個對寫論文也是如此。只說自己的結果比基線好多少隻能說明這是不錯的工作，但結果再好並不能意味這個工作有深度。</p>
<p>深度學習的火熱導致了各種巨資收購初創司不斷。Alex 也有點按耐不住， 結果是他，Dave，Ash（曾經是 YahooCTO）和我合夥弄了一家公司，拿了幾十萬的天使投資就開工了。Alex 寫爬蟲，Dave 寫框架，我跑模型，風風火火幹了好一陣子。可惜中途 Dave 跑路去跟 Jeff 做 TF 了。後來這個公司賣給了一個小上市公司。再後來我們覺得這個公司不靠譜也就沒考慮跟他們幹了。</p>
<p>第一次創業不能說很成功，從中學到幾點：一是跟教授開公司一定要注意有太多想法但沒死死的掐住一個做，二是找一堆兼職的博士生來幹活不是特別靠譜，尤其是產品不明確的時候，三是即使要賣公司也一定要做一個產品出來。我們賣的時候給很多人的感覺是團隊人太強但產品太弱，所以他們只想要人而已。四是試圖想要通過技術去改變一個非技術公司是很難的事情，尤其是過於新的技術。</p>
<p>然後我們就奔去折騰下一個公司。Ash 早財務自由所以想做一個大的想法，但這時 Alex 剛在灣區買了個房，有還貸壓力，他選擇去了 Amazon。於是算是胎死腹中。</p>
<p>隨後收到 Jeff 的郵件說有沒有興趣加入 Google，自然這是一個很誘人的機會。同時我覺得小的創業技術性強的公司是不錯的選擇。但從 MXNet 的發展上來書，去 Amazon 是最好選擇之一。自己挖的坑，總是要自己填的。所以我以兼職的身份去了 Amazon，領着一幫小弟做些 MXNet 開發和 AWS 上深度學習的應用。</p>
<p><strong>第五年：9/16-2/17</strong></p>
<p>早在 15 年初 Alex 就表示我可以畢業了，但作爲拖延晚期患者，遲遲沒開始準備。這時候感覺不能再拖了，於是窩在灣區寫畢業論文。Alex 覺得畢業論文應該好好寫，但我對把前面都做完的東西再搗鼓寫寫實在是沒興趣，尤其是加州太陽那麼好，大部分時間我都是躺在後院曬太陽。此時 B 站已經完全被小學生佔領，這邊買書也不方便，無聊之餘刷了很多起點。然後還寫了篇<a class="internal" href="https://zhuanlan.zhihu.com/p/23781756">煉丹文</a>。</p>
<p>CMU 要求答辯委員會需要有三個 CMU 老師和一個學校外的。除了兩個導師外，我找了 Jeff Dean 和剛加入 CMU 的 Ruslan Salakhutdinov. 結果 Russ 隨後就加入了 Apple，整個委員會的人都在灣區了。Jeff 開玩笑說可以來 Google 答辯。可惜跟 CMU 爭吵了好多次，還是不允許在校外答辯，而且必須要三個人委員會成員在場。這些限制導致答辯一拖再拖，而且臨時加了 Barnabas Poczos 來湊人數。最後是 Jeff 的助理快刀斬亂麻的協調好了時間把所有東西定好了。沒有她估計我還可以拖幾個月。</p>
<p>答辯的時候是一個比較奇異的狀態，委員會裏有 Google, Amazon, Apple 的 AI 負責人，剩下兩個和我又分別在這三家公司兼職。這個反應了當下 AI 領域學術界紛紛跑去工業界的趨勢。</p>
<p>不過答辯這個事情倒是挺簡單，跟平常做個報告沒什麼太多區別。一片祥和，即使 Russ 問了 MXNet 和 TensorFlow 哪家強這個問題也沒有打起來。</p>
<p>答辯後我問委員會說，我在考慮找個學術界的工作，有什麼建議沒。大家介紹了一大堆經驗，不過大家都強調的一個重點是：學術界好忙好忙，而且好窮好窮，工業界的薪水（就差指自己臉了）分分鐘秒掉 CMU 校長。你要好好想。</p>
<p><strong>總結</strong></p>
<p>答辯前一天的晚上，我想了兩個問題，一個是“博士收穫最大的是什麼”，另一個是“如果可以重來會怎麼辦”。對於第一個問題，這五年時間自然學到了很多東西，例如系統的學習了分佈式系統，緊跟了機器學習這五年的發展，寫文章做幻燈片做報告水平有提升，代碼能力也加強了些。自信上有所提高，覺得既可以做一流的研究，也可以寫跟大團隊 PK 的代碼。只要努力，對手沒什麼可怕的。</p>
<p>但更重要的是博士的五年的時間可以專注的把一些事情從技術上做到最好，做出新的突破，這個氛圍沒有其他地方能給予。</p>
<p>第二個問題的一個選項是當年留在國內會怎麼樣？ 當年百度的夥伴們多數現在都做得很好，都在引領這一波 AI 的潮流，甚至有好幾個創造了上億價值的公司。所以從金錢或者影響力角度來看，一直在工業界也不差，說不定現在已經是土豪了。</p>
<p>不過我覺得還是會選擇讀博。賺錢以後還有大把時間可以，但是能花幾年時間在某個領域從入門到精通甚至到推動這個領域發展的機會就一次。站在這個領域的高點會發現世界雖然很大，但其實其他領域也使用差不多的技術，有着同樣的發展規律。博士期間領悟到的學習的方法可以在各個方向上都會大有作爲。</p>
<p>更重要的是理想和情懷。人一生要工作五十年，爲什麼不花五年來追求下理想和情懷呢？</p>



</div>
</div>
</div>


</div>
</div><script type="“text/javascript”">window.daily=true</script>