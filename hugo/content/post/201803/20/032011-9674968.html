+++
date = "2018-03-20T11:00:00"
title = "自動駕駛 Uber 撞死行人，爲什麼說這類事故發生是遲早的事？"
titleimage = "https://pic3.zhimg.com/v2-a2f1a70855b4cec88f156671d31416aa.jpg"
ga = 032011
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



<div class="headline-background">
<a class="headline-background-link" href="http://tech.163.com/18/0320/11/DDBAABPR00097U80.html">
<div class="heading">相關新聞</div>
<div class="heading-content">警方迴應無人車撞人致死：初步調查顯示 Uber 無過錯</div>
<i class="icon-arrow-right"></i>
</a>
</div>

</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">Uber 全球第一起自動駕駛致其死亡的不幸事件發生，反映了哪些問題？會有何影響？</h2>

<div class="answer">



<div class="content">
<p>這個算是第一個公衆眼裏的 AI 致死事件，也是意料之中的事情，Anything that can go wrong will go wrong. 爲死者惋惜。</p>
<p>這個事件帶來兩個核心問題，一個是<strong>爲什麼事故會發生</strong>，另外一個是<strong>到底是誰的責任</strong>。</p>
<p>爲什麼事故會發生，簡單來說是 AI 作出錯誤決策導致事故發生，那到底爲什麼 AI 會作出錯誤決策，這就涉及 AI 模型的可解釋性(explainability)和透明性(transparency)。目前連圖片分類神經網絡的解釋性都還沒解決，對於自動車如此複雜的系統，要解釋明白爲什麼沒檢測到行人以及爲什麼沒有制動，我覺得是個非常難的問題，因爲我自己的一個研究方向就是 AI 模型的可解釋性。解釋 AI 模型的決策還任重道遠，好在這兩年大家也意識到了這個問題的重要性，相關研究工作多了起來，比如說美國國防部<a href="https://www.darpa.mil/program/explainable-artificial-intelligence">DARPA 的 Explainable AI 研發項目</a>，就是力求開發出更具有解釋性的模型。</p>
<p>AI 模型解釋性也涉及 AI 的立法管理。去年歐盟就頒佈了一個法令 GDPR (General Data Protection Regulation)，其中一項是<a href="https://news.sophos.com/en-us/2017/05/22/gdprs-right-to-explanation-the-pros-and-the-cons/">Right to Explanation</a>: a user can ask for an explanation about an algorithmic decision made about them。大概意思是，民衆有權利要求機器算法解釋其作出決策的原因，也是希望提出的 AI 模型能更具透明性和可解釋性。關於此次事故的技術調查，我也會繼續關注。</p>
<p>這次事件帶來的另外一個問題是，人命關天到底是誰的責任。自動駕駛汽車出了事故，責任是屬於汽車所有人？操作員？乘客？生產車廠商？還是 AI 算法科學家？程序員？或者背鍋臨時工？這是個非常困難的問題，而且並沒有相應的法規和立法。這個問題，深層次又涉及 AI 的倫理。比如說讓 AI 來解這個倫理學上的經典問題<a href="https://en.wikipedia.org/wiki/Trolley_problem">Trolley Problem</a>，機器又會做出如何的選擇。</p>
<p>打個岔，針對這個 Trolley 問題， MIT 的 media lab 搞了個挺有意思的實驗平臺<a href="http://moralmachine.mit.edu/">Moral Machine</a>：其在上面設計出了一些場景，讓人來思考自動駕駛系統會作出如何的決策。比如說下面第一個場景是，一個失控的自動駕駛系統，如果繼續前行的話會造成 5 個嬰兒死亡，轉左的話會造成 2 名乘客死亡，那算法應該如何作出決策？第二個場景是自動車直行造成一部分行人受傷，左轉的後果不確定（有可能造成行人傷亡，有可能無恙），那算法又該作出怎樣的決策呢？研究 AI，並不一定需要非常 technical，這種從心理學倫理學社會學出發，也是一條路子。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-1497e7497fbf02a84dc39b2df5f94b13_b.jpg" alt="">
<img class="content-image" src="http://pic2.zhimg.com/70/v2-f264d7d5dd211da4bccd425354dfe02d_b.jpg" alt="">
<p>總的來說，AI 造成傷亡事故，和 AI 戰勝人類最優秀的圍棋選手，都是發展過程中的必然。其造成的影響，暴露出的問題，長遠來看還是對 AI 的發展，和人類社會針對 AI 的立法倫理都有積極推動意義。</p>
</div>
</div>




</div>





<div class="question">
<h2 class="question-title"></h2>

<div class="answer">



<div class="content">
<p>可能要從兩個方面思考這個問題：</p>
<p>首先 Uber 無人車撞人致死和自動駕駛是否真的安全，沒有必然聯繫；</p>
<p>第二，Uber 只是自動駕駛玩家之一，而且也不是最優秀技術的代表。</p>
<p>一個個說。</p>
<p>1）Uber 無人車撞人說明了啥？</p>
<p>只能說明 Uber 無人駕駛技術實在不怎麼樣。</p>
<p>先給大家介紹下事故始末：</p>
<p>美國上週日 22 點，在氣候宜人、自動駕駛政策友好的亞利桑那州郊區路段，一名 49 歲的女性行人沒有通過人行道而希望橫穿馬路（違章過馬路），被被 Uber 無人駕駛測試車撞倒，送醫搶救後死亡。</p>
<p>當時 Uber 無人車的情況是：車改裝自沃爾沃 XC90 SUV，後添加了 Uber 自主研發的軟件系統，使用了包括激光雷達、相機在內的傳感器，確實是目前較爲主流的自動駕駛方案。</p>
<p>並且，事故發生時，Uber 無人車上有人，但坐於後座。據稱車速 60 公里\小時，沒有剎車減速。</p>
<p>OK，事故目前細節基本就是這樣。</p>
<p>可以看出這麼幾個問題：1）週末夜晚，路況不錯，環境不錯；2）行人在非人行橫道突發闖路；3）Uber 無人車系統完全沒有識別、感知和決策。</p>
<p>所以也可以得出基本結論：悲劇的原因非常明顯——Uber 自動駕駛技術實在太差了！</p>
<p>在 L4 等級（完全無司機參與）的自動駕駛中，對於行人的識別是最基本、最必須的要求，雖然始發時間是夜晚（可能會影響相機發揮作用），但裝有激光雷達的 Uber 無人車，至少應該做到有效識別，然後減速\剎車。</p>
<p>但 Uber 無人車都沒有，直接撞了過去。</p>
<p>有人可能說是行人違章過馬路，但假如連這樣的場景都解決不了，是不是自動駕駛以後要專門建設防行人穿過的車道？那我們要不直接建地鐵\輕軌？</p>
<p>而且 Uber 也不是第一次發生事故了。</p>
<p>去年 3 月，也是在亞利桑那州，一輛 Uber 無人車發生車禍。</p>
<p>據 ABC 15 新聞臺當時從當地警方得到的消息，警方沒有接到車禍中受傷的報告，事故發生的原因是一輛人類駕駛的汽車沒有及時減速。當時，Uber 的自動駕駛汽車沒有載客，駕駛座上有一名人類，但不清楚當時是人類還是計算機在開車。</p>
<p>Uber 隨後也表示“沒有人嚴重受傷”，公司也正在對事故進行調查。在此過程中，Uber 在亞利桑那、舊金山和匹茲堡的自動駕駛測試項目都暫停運行。</p>
<p>2）自動駕駛真的安全嗎？</p>
<p>不同於其他技術，自動駕駛人命關天，0.000001%的缺陷，都可能造成 100%的傷害，所以自動駕駛不會是絕對安全，有保障的技術。</p>
<p>然而，Uber 無人車撞人致死，與自動駕駛是否安全沒有直接聯繫。</p>
<p>因爲 Uber 不代表最先進技術的發展水平。</p>
<p>誰能代表呢？谷歌的 Waymo。</p>
<p>前些日子，Waymo 宣佈無人車實際路測里程達到了 500 萬英里（800 萬公里）——相當於繞地球地道跑了 200 圈。這是一個前無古人的數據，而且沒有發生撞人致死的事故。</p>
<p>並且還是在亞利桑那州，Waymo 去年試運行了一年，很多普通居民感受到了無人駕駛出行的魅力——晝夜不停、全年無休。</p>
<p>值得說明，一次事故都沒有發生哦。Waymo 今年還希望正式推出無人駕駛出租車打車服務。但現在經 Uber 無人車這麼一撞，感覺要很被動了。</p>
<p>說 Uber 是無人駕駛產業的豬隊友，一點不爲過。</p>
<p>當然，即便 Uber 無人車此次發生致命事故，你也不能說自動駕駛不安全。</p>
<p>因爲相比人類司機，自動駕駛系統可能更安全，從邏輯上講，人類會疲勞、會喝酒、會有一些有的沒的注意力不集中的時候，但計算機完全沒有這樣的問題。</p>
<p>從現實數據來說，光美國一年在交通事故中喪生的人數，平均每天就有 16 人。</p>
<p>但你不會看見任何報道。</p>
<p>而從 Google 開始搞無人車至今，差不多 10 年了，今天豬隊友 Uber 發生了史上第一起撞人致死的案件。</p>
<p>然後被全球矚目。</p>
<p>如果僅憑此認爲自動駕駛不安全，是完全沒有道理的。</p>
<p>最後的最後，還是要哀悼這位名叫伊萊 - 恩赫茨伯格（Elaine Herzberg）的逝者，如果說一點積極的意義，那可能這次會讓人們更加關注自動駕駛帶來的影響，也會更積極地思考自動駕駛遭遇類似問題時，需要解決的問題。</p>
<p>當然，其中最不希望的就是因噎廢食。</p>
</div>
</div>

<div class="answer">



<div class="content">
<p>目前具體事故的細節還不清楚，我先大概說說。等到有更多細節信息之後，再進行補充。</p>
<p>以現有的技術條件，無人駕駛撞死行人的事故是遲早會發生的。之前唯一的問題是，什麼時候會發生？</p>
<p>爲什麼說無人駕駛撞死行人的事故遲早會發生？從大的角度來看，任何技術都不可能是百分之百可靠的。隨着無人駕駛測試里程的增加，出現致命事故的可能性也會大大增加。假設一萬公里里程測試中的無人駕駛出現致命事故的概率是 0.1%，那麼里程達到一億公里時，無人駕駛出現致命事故的概率會達到 (1 - 0.999^10000) ≈ 100%。數字不準確，但是基本原理如此。無人駕駛的致命事故是可以預期、一定會發生的事情。不要覺得一萬公里和一億公里差了很多，Uber 可是要從沃爾沃購買 24000 輛車的。</p>
<p>// 以下部分爲目前的推測，在事故細節披露之後會進行修改</p>
<p>具體到這次事故，目前還沒有細節信息透露出來。根據已有的一些信息，我做一些大膽的<strong>揣測</strong>。由車輛停車位置還有撞擊痕跡來看，事故很可能是由行人沒有注意到後方來車，突然左轉橫穿馬路造成的。根據警方發佈會的初步信息，當時 Uber 車的車速是 40 英里每小時，也就是說 Uber 車並沒有因爲行人而減速。根據現場事故圖片可以注意到，行人開始左轉的時候，很可能已經處在 Lidar 的盲區。而車上 Lidar 以外的其他傳感器很可能並沒有識別出“推着車 / 騎着車的行人正在左轉”。車上算法認爲行人仍然在直行，最終撞了上去。或者也可能傳感器正確識別了行人，算法做出了反應，但是由於車速過快，車沒有能夠及時停下。</p>
<p>這讓人想起了 Uber 之前的一次無人駕駛事故（車被撞翻了）。兩次事故可能的共同之處在於，無人駕駛車輛的行爲是合法的，但是又是不合常理的、不符合人開車的通常習慣的。具體到這次事故。事故雖然很可能是行人的行爲導致的，但是如果是人駕駛的車輛的話，通常不會在人行道有人行走的情況下，以 40 英里每小時的速度通過臨近道路。考慮到安全因素，人駕駛的車輛，或者會減速，或者會考慮往左進行一些避讓。</p>
<p>//</p>
<p>有人提到了車上實際上是坐着安全員的。安全員的設置，並不能防止這種事故發生。事實上，無人駕駛的安全員作出反應的時間，是比人類駕駛員自己開車的反應時間更長的。這是在討論 ADAS 或者低級別自動駕駛時，經常提到的 Over-trust 問題。這個問題具體展開講太大了，就不細說了。</p>
<p>最後作爲一個業內人士，我一直對無人駕駛持非常保守的態度。在這種和生命直接相關的技術領域，重要的不是知道技術能做什麼，而是理解技術還不能做到什麼。這兩年國內的無人駕駛相關公司都在瘋狂鼓吹快速落地商業化，然而這項技術目前並沒有那麼成熟。也希望這次事故，能讓同行們引以爲戒。</p>
</div>
</div>




</div>


</div>
</div><script type="“text/javascript”">window.daily=true</script>