+++
date = "2018-03-07T12:00:00"
title = "別人享受低價，你作爲店家熟客，卻要被宰（還不知道）"
titleimage = "https://pic1.zhimg.com/v2-9110385d578d94e668e1835afbd8bf40.jpg"
ga = 030712
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



<div class="headline-background">
<a class="headline-background-link" href="http://tech.qq.com/a/20180305/003245.htm">
<div class="heading">相關新聞</div>
<div class="heading-content">300 元的房間給熟客 380元：「大數據殺熟」</div>
<i class="icon-arrow-right"></i>
</a>
</div>

</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>相關問題描述：</p>
<blockquote>
<p>最近，一段自曝被大數據“殺熟”的微博火了。網友“廖師傅廖師傅”表示，他經常通過某網站訂某個特定酒店的房間，長年價格在 380 元 ~ 400 元。偶然一次，他從前臺得知酒店淡季的價格在 300 元上下。他用朋友的賬號查詢也是 300 元，但用自己的賬號查，還是 380 元。網友也紛紛曬出了自己被宰的經歷，大罵企業無良，不少媒體認爲大數據殺熟是技術走了歪路，要有法律制裁才行。</p>
</blockquote>
</div>
</div>


</div>





<div class="question">
<h2 class="question-title">如何看待大數據殺熟？</h2>

<div class="answer">



<div class="content">
<p>今年 Job Market 上正好有一篇 JMP 討論了這個問題：</p>
<p><a href="https://web.stanford.edu/~shota2/shotaJobMarketPaper.pdf">Online Privacy and Information Disclosure by Consumers</a></p>
<p>作者是斯坦福大學的 Shota Ichihashi。</p>
<p><strong>如果顧客的注意力有成本（所以無法比較所有商品），同時企業利用的大數據技術能比顧客更瞭解顧客時，顧客是否有動力向企業提供自己的隱私？</strong>一方面，企業的大數據技術能夠更好地向顧客展示適合他們的商品（以免去他們跑斷腿之苦），但另一方面，顧客也承擔了被價格歧視的風險。</p>
<p>作者假設，企業可以先選擇是否“承諾”不進行價格歧視；在觀察到企業的“承諾”後，顧客決定是否提供，以及提供多少隱私信息；隨後，企業向顧客展示一件商品及價格，顧客決定買或不買。</p>
<p>如果企業承諾不進行價格歧視，則商品的價格在顧客提供隱私信息之前就已經決定好並公開；反之，如果企業選擇進行價格歧視，則企業在觀察到顧客的隱私後才進行定價。</p>
<p>對於企業來說，承諾不進行價格歧視能夠讓顧客提供更多的信息，因此能夠提供更適合顧客的商品，但是由於價格已經固定，利潤也隨之固定了；反之，不承諾的話，雖然可以進行價格歧視，但是由於顧客會相應地減少信息，企業在展示商品時有更更高的風險顧客不願意購買。</p>
<p>在文章的設定下，作者得到了以下結論：</p>
<ol><li><strong>企業傾向於承諾不進行價格歧視，激勵顧客提供更多隱私信息；</strong></li>
<li><strong>不進行價格歧視的行爲降低了消費者剩餘（因爲企業在定價時不瞭解顧客的偏好，定價將會過高），如果允許顧客在企業選擇是否價格歧視之前“承諾”透露多少隱私消息，反而能夠提高消費者剩餘。</strong></li>
</ol><p>作者的其中一個假設“不同商品的邊際成本相同”我不太認同，這一假設保證了企業與顧客在“向顧客展示最適合的商品”（同時也是“最賺錢的商品”）這一點上有着共同利益（進而影響了其關於消費者福利的一些結論）——反之，<strong>如果商品的邊際成本不同，就可能出現企業向顧客展示的並非是“最適合的商品”而是“最賺錢的商品”這種衝突</strong>。</p>
<p>而如果我們總結一下本問題下的回答，可以注意到另一個現象：<strong>顧客的注意力成本不僅體現在他們無法比較充分多的商品</strong>，而只能關注一部分商品（作者用“企業只能展示一件商品”來表現了這種注意力成本），同時也體現在<strong>他們很難意識到企業正在進行價格歧視</strong>。</p>
<p>我之前的回答中寫到過：</p>
<p><a href="https://www.zhihu.com/question/64153985/answer/222608651">Richard Xu：爲什麼經濟發展程度相差很大的兩個城市 麥當勞之類的連鎖店物品沒有差價其中有什麼經濟學原理？</a></p>
<blockquote>5）fairness concerns：<strong>同一品牌不同店面的價格不同可能會導致消費者的差評</strong>，也就是說，如果我習慣了家門口某家店面的價格，到了另一個地方，我會預期該品牌的店面對於同一商品有相似的價格。<br>6）firm learning：<strong>最後一個解釋是隨着數據的累積，品牌正在學習如何根據彈性定價；然而我們並沒有觀察到這樣的趨勢，所以這一解釋也被否定了。</strong>（現場有教授提到 Amazon 最近收購了 Whole Foods，可以期待一下 Amazon 是否會採取彈性定價而非統一定價的方式）</blockquote>
<p>在上述 JMP 當中，作者也寫到：</p>
<blockquote>This potentially explains why price discrimination by online sellers seems to be uncommon, which, empirically, has been puzzling.<br>（結論 1）潛在地解釋了<strong>“在線商家很少進行價格歧視”這一在實證上困擾了經濟學家許久的現象</strong>。</blockquote>
<p>“大數據殺熟”並不算什麼新鮮手段（三級價格歧視），也不是什麼有趣的問題——相反，<strong>爲什麼商家不採取這一手段</strong>，是因爲消費者會“懲罰”不公平的定價，還是因爲商家希望能夠更好地“服務”用戶來提高利潤，纔是更讓經濟學家感興趣的問題。</p>
</div>
</div>

<div class="answer">



<div class="content">
<p>最近一直在看「算法歧視」方面的資料，所謂的「大數據殺熟」其實也是一種算法歧視。應該說這是商業算法運作一定會出現的問題，原因很簡單算法對你瞭解的越清楚，越能估算出你所能承擔的價格。看到不少知友都在批駁這種殺熟的方式，但我們不妨換個角度考慮一下：如果酒店的價格不採用這種普遍的方式，而採用競拍的方式，那麼這種依靠算法分析每個受衆的價格底線，自然就是一種合理的行爲。由此可能出現兩種結果：一種是你能承受的價格底線高於平均水平，還有一種可能是你可以通過競拍機制拿到「低價高質」的酒店。</p>
<p>從這個角度來說，大數據殺熟沒有錯，錯的應該是酒店的「價格機制」。</p>
<p>當然在酒店價格機制沒有改變的情況下，通過商業算法歧視殺熟的行爲在法律上有一定的過錯，表現爲消費者和酒店達成的協議存在「顯失公平」之處，消費者據此可以請求解除或者變更與酒店的協議。</p>
<p>但在實際操作上其實有不少障礙：首先，算法殺熟都是很隱蔽的行爲，除非你和同事一起，你被殺熟了，結果他沒事，容易做對比，否則單個消費者沒有參照標準，也不會發覺自己被殺熟了；其次，正如剛剛提到的，算法殺熟是基於消費者消費習慣、價格承受底線的瞭解，即便被殺熟了，也會是在消費者可以承受的範圍之內，不可能會出現別人一晚 300 元，熟人一晚 3000 元的過大差距；最後是維權的成本，這類案件往往損失不會太大，找酒店協商的話也容易促成酒店按照正常價格調整，從個人層面來說不會引發太大的糾紛。</p>
<p>當然，從社會導向來說，我們的生活越愛越多地受算法控制，淘寶的推薦系統、今日頭條的信息推送、酒店的價格分層都是算法主導的結果。而算法從誕生之初一直伴隨着算法歧視，一方面作爲算法基礎的數據本身存在的歧視；另一方面是算法設計中存在的歧視行爲，算法殺熟就屬於後者。</p>
<p>類似於殺熟這類推薦算法，歧視的危害還不是太明顯，但是如果將算法應用在犯罪評估、信用貸款、僱傭評估等關切人身利益的場合，因爲它是規模化運作的，並不是僅僅針對某一個人，可能影響具有類似情況的一羣人或者種族的利益，造成的危害可能是巨大的。</p>
<p>而且，算法決策的一次小的失誤或者歧視，會在後續的決策中得到增強，可能就成了連鎖效應，這次倒黴了，後面很多次都會跟着倒黴，第一次被殺熟，你接收了；第二次、第三次、第四次可能會持續地被殺熟。</p>
<p>但遺憾的是當前我們法律中並沒有關於算法歧視的相關立法，正如殺熟這種行爲當前還多是依靠個人按照《合同法》的相關規定去維權，而對社會整體層面的算法歧視目前沒有明確的法律規定。</p>
<p>在這點上我們也希望官方能否儘快出臺相關的法律法規，對算法歧視和算法倫理做出相應的法律規制。</p>
</div>
</div>




</div>


</div>
</div><script type="“text/javascript”">window.daily=true</script>